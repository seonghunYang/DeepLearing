{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.5351355 [[1.8956767]\n",
      " [1.3761429]]\n",
      "100 0.70770717 [[0.6121763]\n",
      " [0.2957208]]\n",
      "200 0.6990303 [[0.36963058]\n",
      " [0.20039393]]\n",
      "300 0.695766 [[0.23762459]\n",
      " [0.14716938]]\n",
      "400 0.6943215 [[0.15415521]\n",
      " [0.10582322]]\n",
      "500 0.6936766 [[0.10069025]\n",
      " [0.07486861]]\n",
      "600 0.6933867 [[0.06615803]\n",
      " [0.05236334]]\n",
      "700 0.69325584 [[0.04368744]\n",
      " [0.03631803]]\n",
      "800 0.69319654 [[0.02897003]\n",
      " [0.02503319]]\n",
      "900 0.69316965 [[0.01927703]\n",
      " [0.01717393]]\n",
      "1000 0.6931574 [[0.01286341]\n",
      " [0.0117399 ]]\n",
      "1100 0.69315183 [[0.0086033]\n",
      " [0.0080031]]\n",
      "1200 0.6931493 [[0.0057647 ]\n",
      " [0.00544406]]\n",
      "1300 0.69314814 [[0.00386841]\n",
      " [0.00369712]]\n",
      "1400 0.69314766 [[0.00259899]\n",
      " [0.00250749]]\n",
      "1500 0.69314736 [[0.00174781]\n",
      " [0.0016989 ]]\n",
      "1600 0.69314724 [[0.00117628]\n",
      " [0.00115015]]\n",
      "1700 0.6931472 [[0.00079211]\n",
      " [0.00077815]]\n",
      "1800 0.6931472 [[0.0005337 ]\n",
      " [0.00052624]]\n",
      "1900 0.6931472 [[0.00035971]\n",
      " [0.00035573]]\n",
      "2000 0.6931471 [[0.00024251]\n",
      " [0.00024038]]\n",
      "2100 0.6931472 [[0.00016354]\n",
      " [0.00016239]]\n",
      "2200 0.6931472 [[0.0001103 ]\n",
      " [0.00010968]]\n",
      "2300 0.6931472 [[7.439897e-05]\n",
      " [7.407261e-05]]\n",
      "2400 0.6931472 [[5.018758e-05]\n",
      " [5.001319e-05]]\n",
      "2500 0.6931472 [[3.3854416e-05]\n",
      " [3.3769429e-05]]\n",
      "2600 0.6931472 [[2.2837989e-05]\n",
      " [2.2790256e-05]]\n",
      "2700 0.6931472 [[1.5402311e-05]\n",
      " [1.5376927e-05]]\n",
      "2800 0.6931472 [[1.0388069e-05]\n",
      " [1.0373117e-05]]\n",
      "2900 0.6931472 [[7.0159390e-06]\n",
      " [7.0069477e-06]]\n",
      "3000 0.6931472 [[4.728612e-06]\n",
      " [4.724091e-06]]\n",
      "3100 0.6931472 [[3.1699465e-06]\n",
      " [3.1698960e-06]]\n",
      "3200 0.6931472 [[2.1551743e-06]\n",
      " [2.1551239e-06]]\n",
      "3300 0.6931472 [[1.4488584e-06]\n",
      " [1.4488079e-06]]\n",
      "3400 0.6931472 [[9.735077e-07]\n",
      " [9.734572e-07]]\n",
      "3500 0.6931471 [[6.382310e-07]\n",
      " [6.381805e-07]]\n",
      "3600 0.6931472 [[4.4302632e-07]\n",
      " [4.4297585e-07]]\n",
      "3700 0.6931472 [[2.9401414e-07]\n",
      " [2.9396367e-07]]\n",
      "3800 0.69314724 [[1.8970562e-07]\n",
      " [1.8965514e-07]]\n",
      "3900 0.6931472 [[1.4351184e-07]\n",
      " [1.4346136e-07]]\n",
      "4000 0.6931472 [[1.1966989e-07]\n",
      " [1.1961941e-07]]\n",
      "4100 0.6931472 [[9.4337942e-08]\n",
      " [9.4287465e-08]]\n",
      "4200 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "4300 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "4400 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "4500 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "4600 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "4700 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "4800 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "4900 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5000 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5100 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5200 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5300 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5400 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5500 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5600 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5700 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5800 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "5900 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6000 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6100 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6200 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6300 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6400 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6500 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6600 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6700 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6800 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "6900 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7000 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7100 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7200 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7300 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7400 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7500 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7600 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7700 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7800 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "7900 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8000 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8100 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8200 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8300 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8400 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8500 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8600 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8700 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8800 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "8900 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9000 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9100 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9200 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9300 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9400 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9500 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9600 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9700 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9800 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "9900 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "10000 0.6931472 [[8.8377483e-08]\n",
      " [8.8327006e-08]]\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val, w_val = sess.run(\n",
    "                  [train, cost, W], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val, w_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run(\n",
    "              [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.74729276\n",
      "100 0.7110711\n",
      "200 0.70370096\n",
      "300 0.6981116\n",
      "400 0.69353926\n",
      "500 0.6894605\n",
      "600 0.6854824\n",
      "700 0.6812905\n",
      "800 0.6766261\n",
      "900 0.6712775\n",
      "1000 0.6650795\n",
      "1100 0.65791965\n",
      "1200 0.64975166\n",
      "1300 0.6406145\n",
      "1400 0.6306477\n",
      "1500 0.6200893\n",
      "1600 0.6092449\n",
      "1700 0.5984342\n",
      "1800 0.5879377\n",
      "1900 0.5779604\n",
      "2000 0.5686209\n",
      "2100 0.55995846\n",
      "2200 0.5519499\n",
      "2300 0.54452527\n",
      "2400 0.5375808\n",
      "2500 0.5309844\n",
      "2600 0.5245772\n",
      "2700 0.51816916\n",
      "2800 0.511534\n",
      "2900 0.5044069\n",
      "3000 0.49649435\n",
      "3100 0.48749018\n",
      "3200 0.4770763\n",
      "3300 0.46486437\n",
      "3400 0.45032036\n",
      "3500 0.43279523\n",
      "3600 0.41174042\n",
      "3700 0.38702002\n",
      "3800 0.3591201\n",
      "3900 0.32910872\n",
      "4000 0.2983863\n",
      "4100 0.2683652\n",
      "4200 0.24019289\n",
      "4300 0.21460104\n",
      "4400 0.19190136\n",
      "4500 0.17208326\n",
      "4600 0.15493818\n",
      "4700 0.14016536\n",
      "4800 0.12744145\n",
      "4900 0.116459616\n",
      "5000 0.10694721\n",
      "5100 0.098670125\n",
      "5200 0.091431536\n",
      "5300 0.08506839\n",
      "5400 0.07944542\n",
      "5500 0.0744514\n",
      "5600 0.069994144\n",
      "5700 0.06599741\n",
      "5800 0.062397726\n",
      "5900 0.059141956\n",
      "6000 0.056185782\n",
      "6100 0.053491715\n",
      "6200 0.051027976\n",
      "6300 0.048767444\n",
      "6400 0.04668708\n",
      "6500 0.044766948\n",
      "6600 0.042989988\n",
      "6700 0.041341323\n",
      "6800 0.03980805\n",
      "6900 0.038378768\n",
      "7000 0.037043616\n",
      "7100 0.03579388\n",
      "7200 0.034621898\n",
      "7300 0.033520777\n",
      "7400 0.032484435\n",
      "7500 0.03150754\n",
      "7600 0.030585244\n",
      "7700 0.029713182\n",
      "7800 0.028887503\n",
      "7900 0.028104672\n",
      "8000 0.02736151\n",
      "8100 0.026655125\n",
      "8200 0.025982905\n",
      "8300 0.025342561\n",
      "8400 0.024731856\n",
      "8500 0.02414887\n",
      "8600 0.02359175\n",
      "8700 0.023058835\n",
      "8800 0.02254871\n",
      "8900 0.022059891\n",
      "9000 0.021591127\n",
      "9100 0.021141227\n",
      "9200 0.02070906\n",
      "9300 0.020293668\n",
      "9400 0.019894134\n",
      "9500 0.019509422\n",
      "9600 0.019138947\n",
      "9700 0.018781833\n",
      "9800 0.018437438\n",
      "9900 0.018105034\n",
      "10000 0.017784081\n",
      "\n",
      "Hypothesis:\n",
      "[[0.01386741]\n",
      " [0.98078394]\n",
      " [0.9808156 ]\n",
      " [0.01821718]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# xor-nn\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8879125\n",
      "100 0.7062721\n",
      "200 0.6790744\n",
      "300 0.65732014\n",
      "400 0.6356931\n",
      "500 0.6122068\n",
      "600 0.5858222\n",
      "700 0.5559302\n",
      "800 0.5223503\n",
      "900 0.48541918\n",
      "1000 0.44598514\n",
      "1100 0.40526348\n",
      "1200 0.36462408\n",
      "1300 0.3253765\n",
      "1400 0.28859693\n",
      "1500 0.2550212\n",
      "1600 0.2250221\n",
      "1700 0.19865692\n",
      "1800 0.17575467\n",
      "1900 0.15600738\n",
      "2000 0.13904703\n",
      "2100 0.12449688\n",
      "2200 0.11200315\n",
      "2300 0.10124979\n",
      "2400 0.091963165\n",
      "2500 0.083910964\n",
      "2600 0.07689826\n",
      "2700 0.07076298\n",
      "2800 0.065370195\n",
      "2900 0.06060852\n",
      "3000 0.056385003\n",
      "3100 0.05262264\n",
      "3200 0.04925697\n",
      "3300 0.04623416\n",
      "3400 0.04350889\n",
      "3500 0.041043013\n",
      "3600 0.03880422\n",
      "3700 0.036764897\n",
      "3800 0.034901485\n",
      "3900 0.033193916\n",
      "4000 0.031624656\n",
      "4100 0.03017895\n",
      "4200 0.02884354\n",
      "4300 0.027607154\n",
      "4400 0.026459888\n",
      "4500 0.02539307\n",
      "4600 0.024398979\n",
      "4700 0.023470964\n",
      "4800 0.0226029\n",
      "4900 0.02178963\n",
      "5000 0.021026403\n",
      "5100 0.020308897\n",
      "5200 0.019633468\n",
      "5300 0.01899666\n",
      "5400 0.018395409\n",
      "5500 0.017827049\n",
      "5600 0.017289046\n",
      "5700 0.016779147\n",
      "5800 0.016295342\n",
      "5900 0.015835788\n",
      "6000 0.015398741\n",
      "6100 0.014982776\n",
      "6200 0.014586353\n",
      "6300 0.014208268\n",
      "6400 0.013847325\n",
      "6500 0.013502441\n",
      "6600 0.013172623\n",
      "6700 0.012856884\n",
      "6800 0.012554533\n",
      "6900 0.012264636\n",
      "7000 0.011986535\n",
      "7100 0.011719555\n",
      "7200 0.011463008\n",
      "7300 0.011216388\n",
      "7400 0.010979145\n",
      "7500 0.010750821\n",
      "7600 0.010530852\n",
      "7700 0.01031887\n",
      "7800 0.010114462\n",
      "7900 0.009917175\n",
      "8000 0.009726778\n",
      "8100 0.009542813\n",
      "8200 0.009365097\n",
      "8300 0.00919322\n",
      "8400 0.009026971\n",
      "8500 0.008866118\n",
      "8600 0.008710299\n",
      "8700 0.008559376\n",
      "8800 0.008413138\n",
      "8900 0.008271338\n",
      "9000 0.008133814\n",
      "9100 0.008000381\n",
      "9200 0.007870872\n",
      "9300 0.0077451062\n",
      "9400 0.0076228855\n",
      "9500 0.00750421\n",
      "9600 0.007388777\n",
      "9700 0.0072765555\n",
      "9800 0.0071673053\n",
      "9900 0.0070610843\n",
      "10000 0.006957697\n",
      "\n",
      "Hypothesis:\n",
      "[[0.00700286]\n",
      " [0.995209  ]\n",
      " [0.9918259 ]\n",
      " [0.00775862]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# wide xor\n",
    "# xor-nn\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8925264\n",
      "100 0.68124926\n",
      "200 0.6730661\n",
      "300 0.6632364\n",
      "400 0.6504967\n",
      "500 0.6331463\n",
      "600 0.6086891\n",
      "700 0.57285285\n",
      "800 0.51819384\n",
      "900 0.43604082\n",
      "1000 0.32944337\n",
      "1100 0.22619918\n",
      "1200 0.15173686\n",
      "1300 0.10532863\n",
      "1400 0.076886624\n",
      "1500 0.05880571\n",
      "1600 0.046739496\n",
      "1700 0.038307756\n",
      "1800 0.032176204\n",
      "1900 0.027564883\n",
      "2000 0.023997843\n",
      "2100 0.021172475\n",
      "2200 0.01888911\n",
      "2300 0.017011933\n",
      "2400 0.01544567\n",
      "2500 0.014121904\n",
      "2600 0.01299053\n",
      "2700 0.01201388\n",
      "2800 0.011163481\n",
      "2900 0.0104171\n",
      "3000 0.009757429\n",
      "3100 0.009170648\n",
      "3200 0.008645754\n",
      "3300 0.008173737\n",
      "3400 0.0077472487\n",
      "3500 0.007360224\n",
      "3600 0.007007513\n",
      "3700 0.006684983\n",
      "3800 0.006388987\n",
      "3900 0.006116459\n",
      "4000 0.0058648298\n",
      "4100 0.005631865\n",
      "4200 0.005415543\n",
      "4300 0.0052143103\n",
      "4400 0.00502654\n",
      "4500 0.00485107\n",
      "4600 0.004686787\n",
      "4700 0.0045325323\n",
      "4800 0.0043876264\n",
      "4900 0.0042511243\n",
      "5000 0.004122422\n",
      "5100 0.0040007844\n",
      "5200 0.0038858047\n",
      "5300 0.0037768069\n",
      "5400 0.003673475\n",
      "5500 0.003575404\n",
      "5600 0.0034820084\n",
      "5700 0.0033932123\n",
      "5800 0.003308596\n",
      "5900 0.0032278593\n",
      "6000 0.0031507472\n",
      "6100 0.003077004\n",
      "6200 0.0030065256\n",
      "6300 0.0029389963\n",
      "6400 0.0028742813\n",
      "6500 0.0028122906\n",
      "6600 0.0027526948\n",
      "6700 0.0026954035\n",
      "6800 0.0026404615\n",
      "6900 0.002587525\n",
      "7000 0.0025365183\n",
      "7100 0.0024874862\n",
      "7200 0.00244016\n",
      "7300 0.0023944937\n",
      "7400 0.0023504728\n",
      "7500 0.0023079177\n",
      "7600 0.0022668433\n",
      "7700 0.0022271443\n",
      "7800 0.0021887165\n",
      "7900 0.0021515596\n",
      "8000 0.0021155244\n",
      "8100 0.0020806699\n",
      "8200 0.0020468622\n",
      "8300 0.0020141155\n",
      "8400 0.001982311\n",
      "8500 0.0019515076\n",
      "8600 0.0019215264\n",
      "8700 0.0018924719\n",
      "8800 0.0018642542\n",
      "8900 0.001836769\n",
      "9000 0.0018100908\n",
      "9100 0.001784085\n",
      "9200 0.0017588709\n",
      "9300 0.0017342399\n",
      "9400 0.0017102961\n",
      "9500 0.0016869946\n",
      "9600 0.001664276\n",
      "9700 0.0016421251\n",
      "9800 0.0016205567\n",
      "9900 0.0015994814\n",
      "10000 0.0015789588\n",
      "\n",
      "Hypothesis:  [[0.00130144]\n",
      " [0.9982666 ]\n",
      " [0.99867284]\n",
      " [0.00194776]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# deep \n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
